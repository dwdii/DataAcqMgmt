---
title: 'R Performance Study: Summing in Parallel'
author: "Daniel Dittenhafer"
date: "Friday, November 21, 2014"
output: html_document
---
```{r, echo=FALSE}
options(warn=-1)
require(knitcitations, quietly=TRUE)
require(RefManageR, quietly=TRUE)

cleanbib()

cite_options(style="markdown")

bibDoPara <- bibentry(bibtype="Misc", 
             title="Getting Started with doParallel and foreach", 
             author=as.person("Steve Weston, Rich Calaway"),
             year="2014",
             url="http://cran.r-project.org/web/packages/doParallel/vignettes/gettingstartedParallel.pdf")
             
bibSplitSO <- bibentry(bibtype="Misc", 
             title="Split a vector into three vectors of unequal length in R", 
             author=as.person("Simon O'Hanlon"),
             year="2013",
             url="http://stackoverflow.com/a/18406749")

bibRforeach <- bibentry(bibtype="Misc", 
             title="package foreach, version 1.4.1", 
             author="R Core Team",
             organization="R Foundation for Statistical Computing",
             url="http://www.inside-r.org/packages/cran/foreach/docs/foreach")

bref <- c(bibDoPara, bibSplitSO, bibRforeach)

x <- 1
```

This performance study compares a simple task, the summation of a vector of integers, using various techniques in the R language including the old standard `for` loop, base R's vectorized `sum` function, and a `doParallel` package implementation. The `microbenchmark` package is used to perform the timing measurements and visualization of the timing measurements is presented via `ggplot2`.

```{r}
require(microbenchmark, quietly=TRUE)
require(doParallel, quietly=TRUE)
require(ggplot2, quietly=TRUE)
```

I am running on a 4 core laptop, so I will use 3 cores for this experiment, leaving one for keeping my machine reasonably responsive. 

```{r}
detectedCores <- parallel::detectCores()
registerDoParallel(cores=detectedCores - 1) 
print(detectedCores)
```

#### Summing with For Loop ####
The `for` loop to be used in this study is wrapped in the function `forLoopSum` and is defined as follows:

```{r}
forLoopSum <- function(x)
{
  sum <- 0
  for( a in x){
    sum <- sum + a
  }
  return (sum)
}
```

#### Summing the R Way ####
The base R `sum` function will be used as is.

```{r, results="hide"}
sum(x)
```

#### Summing in Parallel ####
For parallelization, the `doParallel` package will provide the interface to base R's `parallel` package as described in `r citet(bibDoPara)`. The split approach used to allocate data amongst various batches is taken from a StackOverflow post `r citep(bibSplitSO)`. Finally, the base R `foreach` function is
used to to iterate over the batches and dispatch them to the parallelizer `r citep(bibRforeach)`.

```{r}
parallelSum <- function(x) {
  
  items <- length(x)
  batches <- detectedCores * 4
  batchSets <- split(x, rep(1:batches, length.out=items))
  
  finalSum <- foreach(b=iter(batchSets, by='row'), .combine="+") %dopar% sum(b)
  
  return (finalSum)
}
```

#### Performance Experiment #### 
Using the functions described above, a microbenchmark experiment is excuted as shown in the following code. Powers of ten (10) are used to measure differences in magnitude of vector size up to 10 million, with 5 executions per size. The results are saved in a data.frame for use in visualization and the appendix.

```{r}
setSize <- c(1, 2, 3, 4, 5, 6, 7, 8)
resultsDF <- data.frame()

# Loop through the set sizes and perform sub-experiment
for(s in setSize) {
  size <- 10 ^ s
  a <- sample(1:20, size, replace=TRUE)
  
  # Validate
  checkSum <- as.integer(sum(a))
  forSum <- as.integer(forLoopSum(a))
  stopifnot(identical(forSum, checkSum))
  stopifnot(identical(parallelSum(a), checkSum))
  
  # Run performance test
  results <- microbenchmark::microbenchmark(forLoopSum(a), 
                                            sum(a), 
                                            parallelSum(a), 
                                            times=5, unit="ms")
  
  # Save results
  agSum <- summary(results)
  agSumPlus <- data.frame(agSum, count = 10 ^ s) 
  
  resultsDF <- rbind(resultsDF, agSumPlus)
}

```
#### Results ####
The following chart shows the execution times for the various summation techniques. 

```{r, echo=FALSE}
require(ggplot2)
g2 <- ggplot(data=resultsDF, aes(x=(count)))
g2 <- g2 + geom_line(aes(y=mean, group=expr, colour=expr), size=1) 
g2 <- g2 + scale_fill_hue(l=40)
g2 <- g2 + theme(axis.text.x = element_text(angle=30, vjust=1))
g2 <- g2 + guides(colour = guide_legend("Legend"))
g2 <- g2 + labs(title="R Performance - sum function", x="vector length", y="Mean Time (ms)")
g2
```

#### Conslusions ####
As you can see, the base R `sum` function is very scalable compared to a standard `for` loop. A bit surprisingly,
batching for parallelization does not improve the execution. Possibly base R is doing something similar under the covers and is optimized for this already, in contrast to my simple batch oriented parallelization which may suffer from non-performant batch determination (maybe the `split` and `rep` functions are eating up time?). This is an area for further investigation. 

See the appendix that follows for more detailed statistics for each of the benchmark executions.  

#### Appendix ####
The following table lists the raw microbenchmark statistics from the experiment.

```{r, result='asis', echo=FALSE}
knitr::kable(resultsDF)
```

### Source Code ###
The raw R markdown code used to produce this performance study can be found 
[on GitHub, in my DataAcqMgmt repository](https://raw.githubusercontent.com/dwdii/DataAcqMgmt/master/Week13/PerformanceStud-RinParallel.Rmd).

#### References ####
```{r, echo=FALSE}
#record_as_cited(bref)

```{r, results='asis', echo=FALSE}
BibOptions(style="html", bib.style="authortitle")
bibliography()
```